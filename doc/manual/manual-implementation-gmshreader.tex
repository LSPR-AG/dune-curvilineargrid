
% \subsection{Structure of .msh files}
% 
% \begin{mybox}
% \begin{lstlisting}
% $MeshFormat
% ver f_type data_size    # This line is mostly irrelevant
% $EndMeshFormat
% $Nodes
% n_vertices
% 1 x y z
% 2 x y z
% .......
% n_vertices x y z
% $EndNodes
% $Elements
% n_elem
% 1 elem_type n_tags (process_tags) v_1 v_2 ... v_N
% 2 elem_type n_tags (process_tags) v_1 v_2 ... v_N
% .......
% n_elem elem_type n_tags (process_tags) v_1 v_2 ... v_N
% $EndElements
% \end{lstlisting}
% \end{mybox}
% 
% \noindent
% where
% \begin{itemize}
% 	\item $ver$             - version of the GMSH file
% 	\item $f\_type$          - type of file (irrelevant)
% 	\item $data\_size$       - size of file (irrelevant)
% 	\item $n\_vertices$      - number of vertices of the mesh
% 	\item $i\ x\ y\ z$         - index of the vertex and its coordinates
% 	\item $n\_elem$          - number of elements of the mesh
% 	\item $elem\_type$       - Integer which determines element type and interpolation order
% 	\item $n\_tags$          - Total number of tags. If $>2$, then have $process\_tags$
% 	\item $process\_tags$    - Tags which determine the process the vertex belongs to. Only if GMSH is told to partition the mesh
% 	\item $v\_1\ v\_2\ ...\ v\_N$ - Indices of interpolatory vertices associated with this element (includes corners)
% \end{itemize}
% \subsection{Parallel Implementation}

From the outset the parallel implementation of the Curvilinear GMSH Reader is targeted at high parallel scalability. It loads the mesh evenly on all involved processes, avoiding master process bottlenecks. The algorithm to achieve this requires reading the mesh file several times on each process:

\begin{mybox}
\begin{enumerate}
  \item VERTEX PASS 1: Skip all vertices, and place file pointer before the element section

  \item ELEMENT PASS 1: Count the total number of elements and boundary segments

  \item ELEMENT PASS 2: Read corners for all elements within the block associated to this process. Given equal splitting of elements across all processes, the process with index $rank$ should read the elements with indices \[interv(rank) = \floor[\Big]{ [rank, rank+1] \cdot N_{elem} / p_{tot} } + 1.\]
        
  \item If partitioning is enabled, partition the elements among all processes. The partitioning uses the \textit{ParMETIS\_V3\_PartMeshKway} function of \ParMETIS{} \citeParMetis{}. It produces contiguous subdomains on each process, with a roughly equal number of elements on each process. \ParMETIS{} naturally also minimizes the number of boundary connections, thus minimizing the number of interprocessor boundaries and the amount of parallel communication necessary at a later stage. We have also implemented support for \ParMETIS{} multiple constraint partitioning capabilities, but, as of time of writing \ParMETIS{} does not guarantee contiguous subdomains for multi-constraint partitioning.
        
  \item ELEMENT PASS 3: Read all data associated with elements on this process partition. Map all faces to the elements sharing them using the sorted global index of the face corners. The elements are written to the grid factory
       
  \item ELEMENT PASS 4: Read all data associated with boundary elements. Determine if the element belongs to this process by looking it up in the available face map. Separate the processed boundaries by boundary tag. Identify which of the boundary tags is associated with the domain boundary by determining the faces that have only one neighboring element across all processes, and sharing this information with all other processes. Thus each process is aware of all volume and boundary tags, even if there are no entities with this tag on the process. The boundary segments are written to the grid factory.

  \item VERTEX PASS 1: Read the coordinates of the vertices associated with the entities present on this process. The vertex coordinates are written to the grid factory.
\end{enumerate}
\end{mybox}

\noindent
The implementation has an option to directly output the processed mesh into $.VTK$ file set for debugging purposes.

% \begin{mybox}
% \noindent
% Currently using brute-force, because it is not much slower than improved for \\
% 
% \noindent
% \uline{Trivial Algorithm: (Complexity $O(12 N_{elem} N_{\beta} / p_{tot}^2)$)}\\
% \textit{Loop over all stored boundary elements $\beta_i$, and over all stored internal elements $E_j$.} \\
% \textit{ If $\beta_i \in E_j$ for some $j$ then store $\beta_i$ }\\
% 
% \noindent
% \uline{Improved Algorithm: (Complexity $O(12 N_{elem} \log_2 (N_{\beta} / p_{tot}) / p_{tot}$)}
% 
% \begin{enumerate}
% 	\item Construct map from boundary vertex index set to boundary id
% 	\item Add all boundaries to the map
% 	\item Loop over each face of all internal elements
% 	\begin{enumerate}
% 		\item If $map[face]$ is non-null, link the element and boundary
% 	\end{enumerate}
% \end{enumerate}
% 
% \end{mybox}	
% 		
% \begin{enumerate}[resume]
% 	\item Add internal elements to factory
% \end{enumerate}
% \begin{mybox}
% 	\begin{itemize}
% 		\item For debugging purposes write each element to a .vtk file using CurvilinearVTKWriter.
% 		\item Add element vertices and global element index to factory
% 		\item If creating grid with boundaries, also pass $internal\_to\_boundary\_element\_linker$. This array stores the indices of boundaries which are connected to this element (if any).
% 	\end{itemize}
% \end{mybox}
